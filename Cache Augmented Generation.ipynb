{"cells":[{"cell_type":"markdown","source":["### Installing Important Modules"],"metadata":{"id":"-ASdoipcwGyR"},"id":"-ASdoipcwGyR"},{"cell_type":"code","source":["!pip install -U bitsandbytes"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ylo_gh42Fm2p","outputId":"6d4acd1f-0a7e-43b3-9cc4-eaa828cbff5a","executionInfo":{"status":"ok","timestamp":1736436156672,"user_tz":-330,"elapsed":5632,"user":{"displayName":"SHIB KUMAR SARAF","userId":"11784079462216008979"}}},"id":"ylo_gh42Fm2p","execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (0.45.0)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.5.1+cu121)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.26.4)\n","Requirement already satisfied: typing_extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (4.12.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.16.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.1.5)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2024.10.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->bitsandbytes) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes) (3.0.2)\n"]}]},{"cell_type":"markdown","source":["### Importing Libraries"],"metadata":{"id":"izQNoPBPv7SU"},"id":"izQNoPBPv7SU"},{"cell_type":"code","source":["import torch\n","from transformers import BitsAndBytesConfig, AutoTokenizer, AutoModelForCausalLM\n","from transformers.cache_utils import DynamicCache\n","import os\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\""],"metadata":{"id":"sPZdUF6Wv6_a"},"id":"sPZdUF6Wv6_a","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Generate Function"],"metadata":{"id":"mcHsquxWGLdB"},"id":"mcHsquxWGLdB"},{"cell_type":"code","execution_count":9,"metadata":{"id":"1IqOLKJvEfVa","executionInfo":{"status":"ok","timestamp":1736436973552,"user_tz":-330,"elapsed":404,"user":{"displayName":"SHIB KUMAR SARAF","userId":"11784079462216008979"}}},"outputs":[],"source":["# Minimal generate function for token-by-token generation\n","def generate(model, input_ids: torch.Tensor, past_key_values, max_new_tokens: int = 50) -> torch.Tensor:\n","    device = model.model.embed_tokens.weight.device\n","    origin_len = input_ids.shape[-1]\n","    input_ids = input_ids.to(device)\n","    output_ids = input_ids.clone()\n","    next_token = input_ids\n","\n","    with torch.no_grad():\n","        for _ in range(max_new_tokens):\n","            out = model(\n","                input_ids=next_token,\n","                past_key_values=past_key_values,\n","                use_cache=True\n","            )\n","            logits = out.logits[:, -1, :]\n","            token = torch.argmax(logits, dim=-1, keepdim=True)\n","            output_ids = torch.cat([output_ids, token], dim=-1)\n","            past_key_values = out.past_key_values\n","            next_token = token.to(device)\n","\n","            if model.config.eos_token_id is not None and token.item() == model.config.eos_token_id:\n","                break\n","\n","    # Return just the newly generated part\n","    return output_ids[:, origin_len:]"],"id":"1IqOLKJvEfVa"},{"cell_type":"markdown","source":["### Dynamic Cache Setup"],"metadata":{"id":"ZBD6NNltGP9O"},"id":"ZBD6NNltGP9O"},{"cell_type":"code","execution_count":2,"metadata":{"id":"UpXP3xKpEfVb","executionInfo":{"status":"ok","timestamp":1736436282535,"user_tz":-330,"elapsed":2,"user":{"displayName":"SHIB KUMAR SARAF","userId":"11784079462216008979"}}},"outputs":[],"source":["# Initializing the DynamicCache mechanism for storing and reusing the modelâ€™s key/value states.\n","torch.serialization.add_safe_globals([DynamicCache])\n","torch.serialization.add_safe_globals([set])\n","\n","def get_kv_cache(model, tokenizer, prompt: str) -> DynamicCache:\n","    # Encode prompt\n","    device = model.model.embed_tokens.weight.device\n","    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device)\n","    cache = DynamicCache()\n","\n","    with torch.no_grad():\n","        _ = model(\n","            input_ids=input_ids,\n","            past_key_values=cache,\n","            use_cache=True\n","        )\n","    return cache\n","\n","# Remove any extra tokens appended by user queries, appended to the original knowledge\n","def clean_up(cache: DynamicCache, origin_len: int):\n","    for i in range(len(cache.key_cache)):\n","        cache.key_cache[i] = cache.key_cache[i][:, :, :origin_len, :]\n","        cache.value_cache[i] = cache.value_cache[i][:, :, :origin_len, :]"],"id":"UpXP3xKpEfVb"},{"cell_type":"markdown","metadata":{"id":"5diLXLveEfVc"},"source":["### Load LLM Model & Tokenizer"],"id":"5diLXLveEfVc"},{"cell_type":"code","execution_count":null,"metadata":{"id":"f3FdvEEMEfVc","collapsed":true},"outputs":[],"source":["def load_quantized_model_and_tokenizer(\n","    model_name = \"mistralai/Mistral-7B-Instruct-v0.1\",\n","    hf_token = \"enter your hugging face access token\"  # Hugging Face token\n","    ):\n","    # Configure quantization for 4-bit loading\n","    quantization_config = BitsAndBytesConfig(\n","        load_in_4bit=True,  # Enable 4-bit quantization\n","        bnb_4bit_compute_dtype=torch.float16,  # Set computation precision\n","        bnb_4bit_quant_type=\"nf4\",  # Use Normal Float 4 (NF4) quantization\n","        bnb_4bit_use_double_quant=True,  # Enable double quantization\n","    )\n","    # Load the pre-trained model with quantization\n","    model = AutoModelForCausalLM.from_pretrained(\n","        model_name,\n","        device_map=\"auto\",  # Automatically allocate model to devices\n","        quantization_config=quantization_config,\n","        token=hf_token,\n","    )\n","\n","    # Load the tokenizer\n","    tokenizer = AutoTokenizer.from_pretrained(\n","        model_name,\n","        token=hf_token,\n","    )\n","    return tokenizer, model\n","\n","tokenizer,model = load_quantized_model_and_tokenizer()"],"id":"f3FdvEEMEfVc"},{"cell_type":"markdown","metadata":{"id":"cV6N8TdEEfVc"},"source":["### Create a Knowledge Base from input file and prepare KV cache"],"id":"cV6N8TdEEfVc"},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bfsUydzrEfVc","outputId":"7fa36eb4-f84d-4427-9f2e-0fe2ce895cb3","executionInfo":{"status":"ok","timestamp":1736436923290,"user_tz":-330,"elapsed":5017,"user":{"displayName":"SHIB KUMAR SARAF","userId":"11784079462216008979"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["KV cache built. Original length: 6904\n"]}],"source":["def prepare_system_prompt(file_path, model, tokenizer):\n","    try:\n","        # Ensure the file exists\n","        if not os.path.exists(file_path):\n","            raise FileNotFoundError(f\"File not found: {file_path}. Please create a file with the necessary context.\")\n","\n","        # Read content from the file\n","        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n","            input_text = f.read().strip()\n","\n","        # Create the system prompt\n","        system_prompt = f\"\"\"\n","        <|system|>\n","        You are an assistant who provides concise factual answers.\n","        <|user|>\n","        Context:\n","        {input_text}\n","        Question:\n","        \"\"\".strip()\n","\n","        # Build and return KV cache\n","        kv_cache = get_kv_cache(model, tokenizer, system_prompt)\n","        origin_len = kv_cache.key_cache[0].shape[-2]\n","        print(f\"KV cache built. Original length: {origin_len}\")\n","        return kv_cache,origin_len\n","\n","    except FileNotFoundError as e:\n","        print(e)\n","        raise\n","    except Exception as e:\n","        print(f\"An unexpected error occurred: {e}\")\n","        raise\n","\n","\n","# Specify file path and prepare KV cache\n","file_path = \"input doc.txt\"\n","kV_cache,origin_len = prepare_system_prompt(file_path, model, tokenizer)"],"id":"bfsUydzrEfVc"},{"cell_type":"markdown","metadata":{"id":"VQjC-WjSEfVc"},"source":["### Ask Questions Reusing the Cache"],"id":"VQjC-WjSEfVc"},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JZos3PhoEfVc","outputId":"e2c455bd-7832-46e9-e995-23a5c8ef0a4c","executionInfo":{"status":"ok","timestamp":1736437731608,"user_tz":-330,"elapsed":1384,"user":{"displayName":"SHIB KUMAR SARAF","userId":"11784079462216008979"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Q1: what is capital of Tamil Nadu?\n","       Answer: Chennai\n"]}],"source":["# 1st query\n","question1 = \"what is capital of Tamil Nadu?\"\n","clean_up(kV_cache, origin_len)\n","input_ids_q1 = tokenizer(question1 + \"\\n\", return_tensors=\"pt\").input_ids.to(device)\n","gen_ids_q1 = generate(model, input_ids_q1, kV_cache)\n","answer1 = tokenizer.decode(gen_ids_q1[0], skip_special_tokens=True)\n","print(\"Q1:\", question1)\n","print(answer1)"],"id":"JZos3PhoEfVc"},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7lzogfXzEfVd","outputId":"ecb5b4b9-0cfc-46a0-ee24-0463e5c06025","executionInfo":{"status":"ok","timestamp":1736437064115,"user_tz":-330,"elapsed":6392,"user":{"displayName":"SHIB KUMAR SARAF","userId":"11784079462216008979"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Q2: Tell me about its History\n","       Answer: Tamil Nadu has a rich history dating back to the Indus Valley Civilization. Archaeological evidence suggests that the region was inhabited by the Dravidians, who are believed to have migrated from Africa to India.\n"]}],"source":["# 2nd query\n","question2 = \"Tell me about its History\"\n","clean_up(kV_cache, origin_len)\n","input_ids_q2 = tokenizer(question2 + \"\\n\", return_tensors=\"pt\").input_ids.to(device)\n","gen_ids_q2 = generate(model, input_ids_q2, kV_cache)\n","answer2 = tokenizer.decode(gen_ids_q2[0], skip_special_tokens=True)\n","print(\"Q2:\", question2)\n","print(answer2)"],"id":"7lzogfXzEfVd"},{"cell_type":"code","source":["# 3rd query\n","question3 = \"Tell me about its Dravidians\"\n","clean_up(kV_cache, origin_len)\n","input_ids_q3 = tokenizer(question3 + \"\\n\", return_tensors=\"pt\").input_ids.to(device)\n","gen_ids_q3 = generate(model, input_ids_q3, kV_cache)\n","answer3 = tokenizer.decode(gen_ids_q3[0], skip_special_tokens=True)\n","print(\"Q3:\", question3)\n","print(answer3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fqrtyyO0wV6i","executionInfo":{"status":"ok","timestamp":1736437878739,"user_tz":-330,"elapsed":7979,"user":{"displayName":"SHIB KUMAR SARAF","userId":"11784079462216008979"}},"outputId":"94e960e9-fc5c-4e7d-8bd1-67326a659cb7"},"id":"fqrtyyO0wV6i","execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Q3: Tell me about its Dravidians\n","Answer: Dravidians are an ethnic group of people who are believed to have originated in the Dravidian Peninsula, which is now southern India. They are known for their distinctive language, culture, and customs, which are different from\n"]}]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.9"},"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}